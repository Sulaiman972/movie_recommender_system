# -*- coding: utf-8 -*-
"""Proyek Akhir: Membuat Model Sistem Rekomendasi

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dfAfOtE_4OC4y-rObBdgBQRDtbehTMTM

# Proyek Akhir: Membuat Model Sistem Rekomendasi
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from google.colab import files

"""## Load Data"""

files.upload()

!unzip 'Movie Recommender System Dataset.zip'

!ls

"""## Data Understanding"""

ratings_df = pd.read_csv('ratings.csv')
movies_df = pd.read_csv('movies.csv')

print('Banyak rating: ', ratings_df.shape[0])
print('Banyak film: ', movies_df.shape[0])

ratings_df

movies_df

"""### Univariate EDA

#### rating variable
"""

ratings_df.info()

ratings_df.head()

ratings_df.describe()

print('Jumlah userId: ', len(ratings_df.userId.unique()))
print('Jumlah movieId: ', len(ratings_df.movieId.unique()))
print('Jumlah data rating: ', len(ratings_df))

"""#### movies variable"""

movies_df.info()

movies_df.head()

print('Jumlah movieId: ', len(movies_df.movieId.unique()))
print('Jumlah film: ', len(movies_df.title.unique()))

"""## Data Preparation

### Data Cleaning

#### Menyamakan Genres
"""

duplicates_df = movies_df[movies_df.title.duplicated(keep=False)].sort_values('title')
duplicates_df

ratings_df.loc[ratings_df['movieId'].isin([6003, 144606])]

gby_id = duplicates_df.groupby(by='title').movieId.apply(list).reset_index()
gby_genres = duplicates_df.groupby(by='title').genres.apply(list).reset_index()

selected_ids = dict()

for rowIndex, row in gby_genres.iterrows():
  genres = row[1]
  ids = gby_id.iloc[rowIndex, 1]
  if len(genres[0]) >= len(genres[1]):
    selected_ids[ids[1]] = ids[0] 
  else:
    selected_ids[ids[0]] = ids[1]
  
selected_ids

new_ratings_df = ratings_df.replace(selected_ids)

new_ratings_df

"""#### Menangani Duplikat"""

new_ratings_df = new_ratings_df.drop_duplicates(subset=['userId', 'movieId'], keep='last')

new_ratings_df

new_ratings_df.shape

"""### Feature Encoding"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = new_ratings_df['userId'].unique().tolist()
print('list userId: ', user_ids)
  
# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)
  
# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = movies_df['movieId'].unique().tolist()
print('list movieID: ', movie_ids)
  
# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieId : ', movie_to_movie_encoded)
  
# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

encoded_rating_df = new_ratings_df.iloc[:, :-1]

# Mapping userID ke dataframe user
encoded_rating_df['userId'] = encoded_rating_df['userId'].map(user_to_user_encoded)
  
# Mapping placeID ke dataframe movie
encoded_rating_df['movieId'] = encoded_rating_df['movieId'].map(movie_to_movie_encoded)

encoded_rating_df

encoded_rating_df.info()

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
  
# Mendapatkan jumlah movie
num_movies = len(movie_encoded_to_movie)
print(num_movies)
      
# Nilai minimum rating
min_rating = min(encoded_rating_df['rating'])
  
# Nilai maksimal rating
max_rating = max(encoded_rating_df['rating'])
  
print('Number of User: {}, Number of movies: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""### Split data"""

# Mengacak dataset
encoded_rating_df = encoded_rating_df.sample(frac=1, random_state=42)
encoded_rating_df

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = encoded_rating_df[['userId', 'movieId']].values
  
# Membuat variabel y untuk membuat rating dari hasil 
y = encoded_rating_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
  
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * encoded_rating_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
  
print(x, y)

"""## Training """

class RecommenderNet(tf.keras.Model):
  
  # Insialisasi fungsi
  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    # layer embedding user
    self.user_embedding = tf.keras.layers.Embedding( 
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf.keras.regularizers.l2(1e-6)
    )
    # layer embedding user bias
    self.user_bias = tf.keras.layers.Embedding(num_users, 1) 
    # layer embeddings movie
    self.movie_embedding = tf.keras.layers.Embedding( 
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf.keras.regularizers.l2(1e-6)
    )
    # layer embedding movie bias
    self.movie_bias = tf.keras.layers.Embedding(num_movies, 1) 
  
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) 
    user_bias = self.user_bias(inputs[:, 0]) 
    movie_vector = self.movie_embedding(inputs[:, 1]) 
    movie_bias = self.movie_bias(inputs[:, 1]) 
  
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
  
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

# inisialisasi model
model = RecommenderNet(num_users, num_movies, 50) 
  
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 16,
    epochs = 20,
    validation_data = (x_val, y_val)
)

"""## Evaluate"""

train_eval = model.evaluate(x_train, y_train, verbose=0)
val_eval = model.evaluate(x_val, y_val, verbose=0)

print('train loss: ', train_eval[0])
print('val loss: ', val_eval[0])
print('train rmse: ', train_eval[1])
print('val rmse: ', val_eval[1])

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Mengambil sample user
user_id = ratings_df.userId.sample(1).iloc[0]
movies_watched_by_user = ratings_df[ratings_df.userId == user_id]
  
# Membuat list movie yang belum pernah ditontin
movies_not_watched = movies_df[~movies_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId'] 
movies_not_watched = list(
    set(movies_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)
  
movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

ratings = model.predict(user_movie_array).flatten()
  
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
]
  
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movies with high ratings from user')
print('----' * 8)
  
top_movie_user = (
    movies_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
  
movies_df_rows = movies_df[movies_df['movieId'].isin(top_movie_user)]
for row in movies_df_rows.itertuples():
    print(row.title, ':', row.genres)

print('----' * 8)
print('Genres user likes: ',end = '')

genres = set()
for row in movies_df_rows.itertuples():
  genres = set.union(set(row.genres.split('|')), genres)

print(genres)

print('----' * 8)
print('Top 10 movies recommendation')
print('----' * 8)
  
recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movies.itertuples():
    print(row.title, ':', row.genres)